{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextualização do Problema e Solução Proposta\n",
    "Costumo ler muitos posts do *medium.com* relacionado a ciência de dados, e a escolha de um bom post para ler acaba demandando muito tempo. Com isso, um **sistema de recomendação de posts do medium** com temas relacionados ao meu interesse, acabaria com a enorme quantidade de tempo perdido para escolher um bom post.\n",
    "\n",
    "Há diversas estratégias para construção de sistemas de recomendação. Existem as baseadas em *filtragem por conteúdo*, *filtragem colaborativa*, porém a que utilizaremos aqui é simplesmente *prever e depois ordenar*.\n",
    "\n",
    "De acordo com as **informações públicas** do medium, pensamos que o *título* é a principal feature para o modelo, e que algumas informações extras do posts também podem dar uma ajudinha para o modelo, como *quantidade de curtidas*, *comentários*, *tempo requerido para ler o post*, enfim, informações de engajamento em geral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo\n",
    "É importante falar qual processo/método guiará esse trabalho. Após a concepção da ideia, debate de principais features a serem capturadas, haverá a exploração e limpeza dos dados, depois a escolha de uma boa métrica, criação de uma baseline, treinamento, otimização dos hiperparâmetros, validação e um pós-processamento nas previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib as jb\n",
    "\n",
    "#VISUALIZAÇÃO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#SCIPY\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "\n",
    "#SCIKIT-LEARN\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.metrics import average_precision_score, roc_curve, roc_auc_score, classification_report, f1_score, precision_recall_curve, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, learning_curve, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#SCIKIT-OPTIMIZE\n",
    "from skopt import dummy_minimize, gp_minimize, BayesSearchCV\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comments</th>\n",
       "      <th>key_word</th>\n",
       "      <th>palms</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "      <th>log_comments</th>\n",
       "      <th>log_palms</th>\n",
       "      <th>log_reading_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>learn data science broke</td>\n",
       "      <td>1</td>\n",
       "      <td>1.812913</td>\n",
       "      <td>4.322240</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>17800.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>build data science portfolio</td>\n",
       "      <td>1</td>\n",
       "      <td>1.892095</td>\n",
       "      <td>4.250444</td>\n",
       "      <td>1.278754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  comments      key_word    palms  reading_time  \\\n",
       "0           0        64  Data Science  21000.0           9.0   \n",
       "1           1        77  Data Science  17800.0          18.0   \n",
       "\n",
       "                          title  target  log_comments  log_palms  \\\n",
       "0      learn data science broke       1      1.812913   4.322240   \n",
       "1  build data science portfolio       1      1.892095   4.250444   \n",
       "\n",
       "   log_reading_time  \n",
       "0          1.000000  \n",
       "1          1.278754  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1465, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha da Métrica\n",
    "A escolha da métrica é **fundamental** para o sucesso do seu projeto! Com a escolha errada da métrica, é bem provável que você otimize o seu modelo para o problema errado, implicando em gasto de tempo, recursos financeiros e até mesmo o fracasso do projeto.\n",
    "\n",
    "Para esse problema, levando em consideração que é um problema binário, levemente desbalanceado, e como os FP (Falsos Positivos) e VP (Verdadeiros Positivos) são importantes, optei pela métrica **Average Precision** (Precisão Média) não interpolada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test\n",
    "Geralmente, a porcentagem indicada na literatura para separar os dados são 70% (train) e 30% (test), outras indicam 80/20... Mas isso **depende** muito da quantidade dos dados que se para trabalhar. A escolha é sempre um **trade-off**, pois mais dados para validação gera mais *confiabilidade* na avaliação do modelo. Já mais dados para treinamento, implica em mais exemplos para o modelo *aprender* melhor (generalizar). Optei por 70/30, pela quantidade de dados em questão, e o processo de validação cruzada adiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['comments', 'palms', 'reading_time', 'title']\n",
    "target = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 4) (440, 4) (1025,) (440,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[features], target, test_size=0.3, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a *feature title* é um texto, optei por uma estratégia comum e simples para uma primeira solução, que é o **TF-IDF** (Term Frequency-Inverse Document Frequency). É uma medida estatística que avalia a relevância de uma palavra de um documento em relação a um conjunto de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train = X_train['title']\n",
    "title_test = X_test['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vec = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "title_bow_train = title_vec.fit_transform(title_train)\n",
    "title_bow_test = title_vec.transform(title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 1791) (440, 1791)\n"
     ]
    }
   ],
   "source": [
    "print(title_bow_train.shape, title_bow_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025, 1794) (440, 1794)\n"
     ]
    }
   ],
   "source": [
    "X_train_wtitle = hstack([X_train[['comments', 'palms', 'reading_time']], title_bow_train])\n",
    "X_test_wtitle = hstack([X_test[['comments', 'palms', 'reading_time']], title_bow_test])\n",
    "print(X_train_wtitle.shape, X_test_wtitle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "X_train_wtitle2 = csr_matrix(X_train_wtitle.copy())\n",
    "X_test_wtitle2 = csr_matrix(X_test_wtitle.copy())\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "X_train_wtitle2[:, :3] = scaler.fit_transform(X_train_wtitle2[:, :3].todense())\n",
    "X_test_wtitle2[:, :3] = scaler.transform(X_test_wtitle2[:, :3].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Uma linha de base é uma solução simples e fácil de ser implementada. É importante para fornecer um ponto de base para comparação com os modelos criados com aprendizado de máquina. Algumas estratégias básicas de baseline para problemas de classificação binária são:\n",
    "* **Palpite Aleatório Uniforme** (Prever 0 ou 1 com probabilidades iguais).\n",
    "* **Palpite Aleatório Anterior** (Prever 0 ou 1 proporcional à probabilidade anterior no conjunto de dados)\n",
    "* **Classe Majoritária** (Prever a classe de maior frequência)\n",
    "* **Classe Minoritária** (Prever a classe de menor frequência)\n",
    "* **Classe Anterior** (Prever a probabilidade anterior a cada classe)\n",
    "\n",
    "Optei pela classe majoritária, por influência da escolha da métrica escolhida para esse problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6431818181818182\n"
     ]
    }
   ],
   "source": [
    "print(average_precision_score(y_test, np.ones(440))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e Validação\n",
    "Nessa etapa, foi realizado uma **busca otimizada bayesiana**, que se mostra geralmente mais eficiente do que outras estratégias de busca para *tuning de hiperparâmetros*. Optei pelos algoritmos *Random Forest*, *Logistic Regression* e *LGBM* nessa primeira solução. Foi realizado uma média aritmética nas previsões, com o intuito de uma estabilidade maior, do que apenas um modelo para decidir sozinho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 30\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "        n_splits=3,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "param_grid_RF = {\n",
    "    'n_estimators': (50, 1000),\n",
    "    'min_samples_leaf': (1, 128),\n",
    "    'min_samples_split': (2, 128),\n",
    "    'max_depth': (1, 128),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "param_grid_LR = {\n",
    "    'tol': (1e-4, 1e-3, 'log-uniform'),\n",
    "    'C': (1e-4, 8),\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': (50, 1100)\n",
    "}\n",
    "\n",
    "param_grid_LGBM = {\n",
    "    'learning_rate': (1e-4, 1e-0, 'log-uniform'),\n",
    "    'n_estimators': (50, 1000),\n",
    "    'colsample_bytree': (0.1, 1.0),\n",
    "    'min_child_samples': (1, 100),\n",
    "    'num_leaves': (2, 128),\n",
    "    'subsample': (0.05, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fit(param_grid, model, X_train, y_train, num_iter=30, cv=3, random_state=5):\n",
    "    \n",
    "    opt = BayesSearchCV(\n",
    "            model,\n",
    "            param_grid,\n",
    "            scoring='average_precision',\n",
    "            n_iter=num_iter,\n",
    "            random_state=random_state,\n",
    "            verbose=0,\n",
    "            cv=cv\n",
    "            )\n",
    "    print(\"Total de buscas:\", opt.total_iterations)\n",
    "    print(\"Treinando...\")\n",
    "    opt.fit(X_train, y_train)\n",
    "    print(\"Pontuações da Precisão Média (CV nos dados de Treino):\", np.mean(opt.cv_results_['mean_test_score']))\n",
    "    print(\"Média das Pontuações da Precisão Média (CV nos dados de Treino):\", np.mean(opt.cv_results_['mean_test_score']))\n",
    "    print(\"Desvio Padrão Precisão Média (CV nos dados de Treino):\", np.mean(opt.cv_results_['std_test_score']))\n",
    "    return opt.best_estimator_, opt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de buscas: 150\n",
      "Treinando...\n",
      "Pontuações da Precisão Média (CV nos dados de Treino): 0.7275142133419121\n",
      "Média das Pontuações da Precisão Média (CV nos dados de Treino): 0.7275142133419121\n",
      "Desvio Padrão Precisão Média (CV nos dados de Treino): 0.017924018207996585\n",
      "Precisão Média (nos dados de Test): 0.8191559292072723\n",
      "Tempo de Execução: 5.86496924161911\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "rf, rf_params = run_fit(param_grid_RF, RandomForestClassifier(class_weight='balanced', random_state=0, verbose=0),\n",
    "             X_train_wtitle2, y_train, num_iter=ITERATIONS, cv=cv)\n",
    "fim = time.time()\n",
    "preds_rf = rf.predict_proba(X_test_wtitle2)[:, 1]\n",
    "print(\"Precisão Média (nos dados de Test):\", average_precision_score(y_test, preds_rf))\n",
    "print(\"Tempo de Execução:\", (fim - inicio)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de buscas: 120\n",
      "Treinando...\n",
      "Pontuações da Precisão Média (CV nos dados de Treino): 0.78712363541303\n",
      "Média das Pontuações da Precisão Média (CV nos dados de Treino): 0.78712363541303\n",
      "Desvio Padrão Precisão Média (CV nos dados de Treino): 0.018635157713820592\n",
      "Precisão Média (nos dados de Test): 0.842546223161273\n",
      "Tempo de Execução: 0.6820167024930318\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "lr, lr_params = run_fit(param_grid_LR, LogisticRegression(class_weight='balanced', random_state=0, verbose=0),\n",
    "             X_train_wtitle2, y_train, num_iter=ITERATIONS, cv=cv)\n",
    "fim = time.time()\n",
    "\n",
    "preds_lr = lr.predict_proba(X_test_wtitle2)[:, 1]\n",
    "print(\"Precisão Média (nos dados de Test):\", average_precision_score(y_test, preds_lr))\n",
    "print(\"Tempo de Execução:\", (fim - inicio)/60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de buscas: 240\n",
      "Treinando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontuações da Precisão Média (CV nos dados de Treino): 0.683822188590133\n",
      "Média das Pontuações da Precisão Média (CV nos dados de Treino): 0.683822188590133\n",
      "Desvio Padrão Precisão Média (CV nos dados de Treino): 0.01815178221965385\n",
      "Precisão Média (nos dados de Test): 0.8108739205879548\n",
      "Tempo de Execução: 10.184617924690247\n"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "lgbm, lgbm_params = run_fit(param_grid_LGBM, LGBMClassifier(class_weight='balanced', subsample_freq=1,\n",
    "                                                            random_state=0, verbose=0), X_train_wtitle2, y_train,num_iter=40, cv=cv)\n",
    "fim = time.time()\n",
    "\n",
    "preds_lgbm = lgbm.predict_proba(X_test_wtitle2)[:, 1]\n",
    "print(\"Precisão Média (nos dados de Test):\", average_precision_score(y_test, preds_lgbm))\n",
    "print(\"Tempo de Execução:\", (fim - inicio)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790992</td>\n",
       "      <td>0.676033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.790992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.676033</td>\n",
       "      <td>0.848669</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LR        RF      LGBM\n",
       "LR    1.000000  0.790992  0.676033\n",
       "RF    0.790992  1.000000  0.848669\n",
       "LGBM  0.676033  0.848669  1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"LR\": preds_lr, \"RF\": preds_rf, \"LGBM\": preds_lgbm}).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443425544695263"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = (preds_lr + preds_rf + preds_lgbm)/3\n",
    "average_precision_score(y_test, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Finais\n",
    "Depois de otimizar os hiperparâmetros dos modelos, optei por realizar o treinamento com todos os dados, afim de obter uma melhor generalização em produção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1465, 2232) (1465,)\n"
     ]
    }
   ],
   "source": [
    "title_vec_final = TfidfVectorizer(min_df=1, ngram_range=(1,1))\n",
    "title_bow_final = title_vec_final.fit_transform(df['title'])\n",
    "\n",
    "scaler_final = MaxAbsScaler()\n",
    "X_scaled = scaler_final.fit_transform(df[['comments', 'palms', 'reading_time']])\n",
    "\n",
    "X_final = hstack([X_scaled, title_bow_final])\n",
    "print(X_final.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.1,\n",
       "               importance_type='split', learning_rate=0.00031605447203434024,\n",
       "               max_depth=-1, min_child_samples=1, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=1000, n_jobs=-1, num_leaves=128,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_final = RandomForestClassifier(**rf_params)\n",
    "rf_final.fit(X_final, target)\n",
    "\n",
    "lr_final = LogisticRegression(**lr_params)\n",
    "lr_final.fit(X_final, target)\n",
    "\n",
    "lgbm_final = LGBMClassifier(**lgbm_params)\n",
    "lgbm_final.fit(X_final, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salvando os vetorizadores, transformadores e modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgbm_20200803.pkl.z']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb.dump(title_vec_final, \"title_vectorizer_20200803.pkl.z\")\n",
    "jb.dump(scaler_final, \"scaler_20200803.pkl.z\")\n",
    "jb.dump(rf_final, \"random_forest_20200803.pkl.z\")\n",
    "jb.dump(lr_final, \"logistic_reg_20200803.pkl.z\")\n",
    "jb.dump(lgbm_final, \"lgbm_20200803.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
